---------------- The reviewers' comments ----------------------

Reviewer 1 [Overall score] 2. not good

[Comment] In this work, authors proposed an automatic synthesis of a pipelined
decoder from a pipelined encoder implementation. 

While the problem is interesting and proposed solution is non-trivial, the
benefit of this approach is not clear from the experimental studies. Compared
to the earlier work, the pipelined decoder generated in this work is ~20%
faster with 5% area loss. This is much like an area-timing trade-off. The
trade-off is actually working worse for the benchmark t2eth.

XXXXXXXXX
The authors should compare their results with a simple retiming/high-level
synthesis that inserts the pipeline automatically, based on some frequency
constraint.


Reviewer 2 [Overall score] 3. average

[Comment] This paper proposes a complementary synthesis algorithm that can
handle pipelined encoders.

The paper is well motivated and the results show the benefit of the proposed
method. 

XXXXXXXXX
Although elegantly written, too much formalism makes it hard to read.

XXXXXXXXX
It is not clear in the experimental results section why benchmarks scrambler
and xfi were included if they have no pipeline stages. Either other designs
should have been included or some synthetic benchmarks could have been added.
It is difficult to extract any meaningful conclusions from only 3 benchmarks. 

XXXXXXXXX
It is also not clear what the input of each testcases is. Is it RTL? References
to the standardization web pages are made .eg. [3] and [8], but those
references do not contain the source code. If so, does your flow parse the RTL
? How does it extract the encoders-decoders? A figure with the complete flow is
required to fully understand the steps in your flow.




Reviewer 3 [Overall score] 3. average

[Comment] This paper addresses the problem of complementary synthesis that
automatically generates a decoder for a given encoder. Basically, this work
extends [10] to identify a decoders pipeline structure and then can
generate a pipelined decoder with better performance than a non-pipelined
decoder.

XXXXXXXXX
The observation and motivation of this work are interesting. However, the
experimental results are not good enough to show the effectiveness and
necessity of the proposed method. Pipelining a decoder could result in much
area overhead. For the t2eth benchmark, by pipelining the decoder, the proposed
method improves only 0.54ns delay, but doubles the area. It is questionable to
pipeline such a decoder.

XXXXXXXXX
Furthermore, although pipelining improves a decoders throughput, it
increases the latency of a single task. That is, more execution time is
required for decoding an input vector. The authors should discuss more on the
usage of a decoder for showing that throughput is a more important
consideration.

XXXXXXXXX
The experimental results show that two out of five encoders have no pipelined
structures. Especially, these two encoders are the larger benchmarks. This
raises a doubt whether an encoder having a pipelined structure is a general
case or not? The authors should show more encoders/benchmarks with pipelined
structures for strengthening the motivation of this work.



Reviewer 4 [Overall score] 3. average

[Comment] This paper proposes complementary synthesis algorithm which can
generate a pipelined decoder from a mapping of input and output of pipelined
encoder. Unlike other works which can only generate combinational logics, the
proposed method can generate pipelined ones and the generated decoder achieves
shorter clock delay.

[Strength]
- First method to generate pipelined decoder.
- The method is theoretically well described.
- Experimental results shows performance improvement compared to an other work.

XXXXXXXXX
[Weakness] 
- In the experiment, # of pipeline stages of the encoders are not shown. In
  order to evaluate the effectiveness of the proposed work, such numbers should
be presented. 

[comment]
- In the experimental result, results of two of five cases (scrambler and xfi)
  are not shown and stated as "no pipeline stages found". I think even if there
is no pipeline stage, at least the work [10] may be able to generate a decoder.
Why is it not shown?


Reviewer 5 [Overall score] 3. average

[Comment] This paper is well written and has theoretic proof to the proposed
algorithm. The experimental results showed the delay of generated pipelined
decoder can be effectively reduced. In Table 1, I suggest to show the pipelined
stages used in the original encoder circuit instead of just showing the number
of registers. It does not show that if the the decoder generated by your
algorithm has the same pipeline stages or not. The paper might discuss this
issue in more detail.

In Sec. V, there is a typo error in the following paragraph: Comparing the 7th
and the 10th column indicates that the decoders' delay have been significantly
improved. And "the the" last column shows that there actually exist very deep
pipeline, especially the t2eth with 4 pipeline stages.  The word "the" repeats
two times.



Reviewer 6 [Overall score] 2. not good

[Comment] Given a pipelined encoder, the proposed method generates a
corresponding pipelined decoder.

My major concern is on the experimental results.

First, there are only 5 designs under test; only 3 of them are pipelined
designs. I suggest more design cases should be examined before drawing a solid
conclusion.

Second, the key idea of pipeline is to increase the speed significantly at the
cost of small area and latency increase. However, if you check the experimental
results, only minor improvent of speed can be observed, whereas the area and
latency get worse significant. Therefore, I cannot agree the authors' claim,
"pipelined decoders with significantly improved speed."
